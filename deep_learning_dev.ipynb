{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16e3a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51babba0",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e3b4ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./train/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train/cifar-10-python.tar.gz to ./train/\n"
     ]
    }
   ],
   "source": [
    "train_data = CIFAR10(root=\"./train/\",\n",
    "                    train=True,\n",
    "                    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4684cc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./train/\n",
       "    Split: Train"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b925df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c80863f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94d25d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 9, 9, 4, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82a6fbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48215574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'automobile': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'deer': 4,\n",
       " 'dog': 5,\n",
       " 'frog': 6,\n",
       " 'horse': 7,\n",
       " 'ship': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23664517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=32x32>, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc4d88c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "train_data[0][0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "283c4714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./test/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./test/cifar-10-python.tar.gz to ./test/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./test/\n",
       "    Split: Test"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the test data as well\n",
    "test_data = CIFAR10(root='./test/',\n",
    "                    train=False,\n",
    "                   download=True)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd14b2ba",
   "metadata": {},
   "source": [
    "### Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ea82534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./train/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               RandomCrop(size=(32, 32), padding=4)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
       "           )"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(.4914,.4822,.4465),\n",
    "        std=(.2023,.1994,.2010)\n",
    "    )\n",
    "])\n",
    "\n",
    "train_data = CIFAR10(root=\"./train/\",\n",
    "                    train=True,\n",
    "                    download=False,\n",
    "                    transform=train_transforms\n",
    "                    )\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5afd51c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./test/\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
       "           )"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(.4914,.4822,.4465),\n",
    "        std=(.2023,.1994,.2010)\n",
    "    )\n",
    "])\n",
    "\n",
    "test_data = CIFAR10(\n",
    "                root='./test/',\n",
    "                train=False,\n",
    "                transform=test_transforms\n",
    "            )\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbfcf4d",
   "metadata": {},
   "source": [
    "### Data Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fb043a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(\n",
    "                train_data,\n",
    "                batch_size=16,\n",
    "                shuffle=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2351633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 32, 32])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve a batch of samples from the training set\n",
    "data_batch, labels_batch = next(iter(trainloader))\n",
    "data_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71bab852",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(\n",
    "                 test_data,\n",
    "                 batch_size=16,\n",
    "                 shuffle=False\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20189485",
   "metadata": {},
   "source": [
    "### General Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57899e33",
   "metadata": {},
   "source": [
    "Image data loading into a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba38fa73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1200, 1600])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load images into the neural network\n",
    "from torchvision import transforms\n",
    "\n",
    "img = Image.open('coffee.jpg')\n",
    "transform = transforms.ToTensor()\n",
    "img_tensor = transform(img)\n",
    "img_tensor.shape  # this is in C*H*W format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebe308d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1200, 1600])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a batch of images\n",
    "N = 1\n",
    "batch = torch.empty(1,3,1200,1600,dtype=torch.uint8)\n",
    "batch[0]=img_tensor\n",
    "batch.shape  # this is in N*C*H*W format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8f5a71",
   "metadata": {},
   "source": [
    "Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04debde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           float64\n",
       "volatile acidity        float64\n",
       "citric acid             float64\n",
       "residual sugar          float64\n",
       "chlorides               float64\n",
       "free sulfur dioxide     float64\n",
       "total sulfur dioxide    float64\n",
       "density                 float64\n",
       "pH                      float64\n",
       "sulphates               float64\n",
       "alcohol                 float64\n",
       "quality                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('winequality_data.csv',sep=';')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a0e61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['quality']\n",
    "X = df.drop('quality',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e98ecdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4898,), (4898, 11))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape , X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c3f6bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 6, 6,  ..., 6, 7, 6])\n",
      "tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
      "        [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
      "        [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
      "        ...,\n",
      "        [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
      "        [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
      "        [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor(y.values)\n",
    "X = torch.tensor(X.values)\n",
    "\n",
    "print(y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d38c3871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.0000e+00, 2.7000e-01, 3.6000e-01, 2.0700e+01, 4.5000e-02, 4.5000e+01,\n",
       "        1.7000e+02, 1.0010e+00, 3.0000e+00, 4.5000e-01, 8.8000e+00],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd091650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity             7.000\n",
       "volatile acidity          0.270\n",
       "citric acid               0.360\n",
       "residual sugar           20.700\n",
       "chlorides                 0.045\n",
       "free sulfur dioxide      45.000\n",
       "total sulfur dioxide    170.000\n",
       "density                   1.001\n",
       "pH                        3.000\n",
       "sulphates                 0.450\n",
       "alcohol                   8.800\n",
       "quality                   6.000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec9b2610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4898, 11])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d416f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
